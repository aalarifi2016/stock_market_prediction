{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "import pandas as pd\r\n",
    "import torch\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import numpy as np\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# previous attept to build model for evrything"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "file_csv = pd.read_csv(\"stock_market_prediction/csv_data/reuters_news.csv\")\r\n",
    "\r\n",
    "# cleaning data by removing raws that has null values in the polarity, subjectivity, or prices columns \r\n",
    "# file_csv.dropna(subset = [\"polarity\"], inplace=True)\r\n",
    "# file_csv.dropna(subset = [\"subjectivity\"], inplace=True)\r\n",
    "# file_csv.dropna(subset = [\"prices\"], inplace=True)\r\n",
    "\r\n",
    "# getting the values of each column\r\n",
    "# polarity = file_csv[\"polarity\"].values\r\n",
    "# subjectivity = file_csv[\"subjectivity\"].values\r\n",
    "# prices = file_csv[\"prices\"].values\r\n",
    "\r\n",
    "\r\n",
    "# making pairwise 2d-array of the polarity and subjectivity arrays\r\n",
    "# polarity = np.array(polarity, dtype=np.float32)\r\n",
    "# subjectivity = np.array(subjectivity, dtype=np.float32)\r\n",
    "# prices = np.array(prices, dtype=np.float32)\r\n",
    "\r\n",
    "\r\n",
    "# devide data into testing, and training, and validation \r\n",
    "x_val = np.array(list(zip(polarity[:5000], subjectivity[:5000])), dtype=np.float32)\r\n",
    "y_val = np.array(prices[:5000], dtype=np.float32)\r\n",
    "\r\n",
    "x_train = np.array(list(zip(polarity[5000:24329], subjectivity[5000:24329])), dtype=np.float32)\r\n",
    "y_train = np.array(list(zip(prices[5000:24329], prices[5000:24329])), dtype=np.float32)    #had to change this for dataloader batch sizes equality, to avoid error\r\n",
    "# y_train.reshape((-1,2))\r\n",
    "\r\n",
    "x_test = np.array(list(zip(polarity[24329:], subjectivity[24329:])), dtype=np.float32)\r\n",
    "y_test = np.array(prices[24329:], dtype=np.float32)\r\n",
    "\r\n",
    "\r\n",
    "# creating the tensors to prepare data for the model\r\n",
    "x_val_tensor = torch.from_numpy(x_val)\r\n",
    "y_val_tensor = torch.from_numpy(y_val)\r\n",
    "y_val_tensor = y_val_tensor.to(torch.float64)\r\n",
    "\r\n",
    "\r\n",
    "# -----------------\r\n",
    "x_train_tensor = torch.from_numpy(x_train)\r\n",
    "# x_train_tensor = x_train_tensor.to(torch.float64)\r\n",
    "y_train_tensor = torch.from_numpy(y_train)\r\n",
    "# y_train_tensor.resize(-1,2)\r\n",
    "# y_train_tensor.view(-1,2)\r\n",
    "# y_train_tensor = y_train_tensor.to(torch.float64)\r\n",
    "# -----------------\r\n",
    "\r\n",
    "\r\n",
    "x_test_tensor = torch.from_numpy(x_test)\r\n",
    "y_test_tensor = torch.from_numpy(y_test)\r\n",
    "y_test_tensor = y_test_tensor.to(torch.float64)\r\n",
    "\r\n",
    "# for i in x_train:\r\n",
    "#     if len(i)<1:\r\n",
    "# for i in x_train:\r\n",
    "#     print(i)\r\n",
    "# train_loader = torch.utils.data.DataLoader(x_train_tensor, batch_size=20)\r\n",
    "\r\n",
    "# x_train_loader = torch.utils.data.DataLoader(x_train_tensor, 64, shuffle=False)\r\n",
    "# iter(x_train_loader).next()\r\n",
    "\r\n",
    "# training_data = np.array(list(zip(x_train, y_train)), dtype=np.float32)\r\n",
    "# training_data = torch.from_numpy(training_data)\r\n",
    "# x_train_loader = torch.utils.data.DataLoader(training_data, 64, shuffle=False)\r\n",
    "# iter(x_train_loader).next()\r\n",
    "# dataloader = torch.utils.data.DataLoader((x_train_tensor, y_train_tensor) , batch_size = 64, shuffle = True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stock_market_prediction/csv_data/reuters_news.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-615bb7462b4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stock_market_prediction/csv_data/reuters_news.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# cleaning data by removing raws that has null values in the polarity, subjectivity, or prices columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# file_csv.dropna(subset = [\"polarity\"], inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# file_csv.dropna(subset = [\"subjectivity\"], inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stock_market_prediction/csv_data/reuters_news.csv'"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# define the model\r\n",
    "class Network(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Network, self).__init__()\r\n",
    "        self.fc1 = torch.nn.Linear(2, 500)\r\n",
    "        self.fc2 = torch.nn.Linear(500, 1000)\r\n",
    "        self.fc3 = torch.nn.Linear(1000, 500)\r\n",
    "        self.fc4 = torch.nn.Linear(500, 50)\r\n",
    "        self.fc5 = torch.nn.Linear(50, 1)\r\n",
    "        \r\n",
    "        self.drop = torch.nn.Dropout(0.2)\r\n",
    "#         self.double()\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.relu(self.fc3(x))\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.relu(self.fc4(x))\r\n",
    "        out = self.fc5(x)\r\n",
    "        return out\r\n",
    "model = Network()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\r\n",
    "critrian = torch.nn.L1Loss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "train_loss = 0.0\r\n",
    "valid_loss = 0.0\r\n",
    "for epoch in range(10000):\r\n",
    "    model.train()\r\n",
    "    \r\n",
    "    for batch in dataloader:\r\n",
    "        x, y = batch\r\n",
    "        \r\n",
    "#         delete the second column from the tensor y\r\n",
    "        y = y.numpy()\r\n",
    "        y = np.delete(y, 1, 1)\r\n",
    "        y = torch.from_numpy(y)\r\n",
    "        \r\n",
    "#         print(y)\r\n",
    "#         break\r\n",
    "#     break\r\n",
    "#         print(y[0][0])\r\n",
    "        # train model\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        output = model(x)\r\n",
    "        loss = critrian(output, y)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        train_loss += loss.item()\r\n",
    "\r\n",
    "# #       break\r\n",
    "# #   break\r\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\r\n",
    "            epoch, \r\n",
    "            train_loss))\r\n",
    "\r\n",
    "    \r\n",
    "#     inputs = Variable(torch.from_numpy(x_train))\r\n",
    "#     labels = Variable(y_train_tensor)\r\n",
    "    \r\n",
    "# #     ---test----\r\n",
    "#     optimizer.zero_grad()\r\n",
    "#     output = model(inputs)\r\n",
    "#     loss = critrian(output, labels.float())\r\n",
    "#     loss.backward()\r\n",
    "#     optimizer.step()\r\n",
    "#     train_loss += loss.item()\r\n",
    "    \r\n",
    "    # train model\r\n",
    "#     optimizer.zero_grad()\r\n",
    "        \r\n",
    "#     output = model(x_test_tensor.float())\r\n",
    "#     loss = critrian(output, y_test_tensor.float())\r\n",
    "#     loss.backward()\r\n",
    "#     optimizer.step()\r\n",
    "#     train_loss += loss.item()\r\n",
    "    \r\n",
    "#     model.eval()\r\n",
    "#     output = model(x_test_tensor.float())\r\n",
    "#     loss = critrian(output, y_test_tensor.float())\r\n",
    "#     valid_loss += loss.item()\r\n",
    "\r\n",
    "#     if (10000%(epoch+1) == 0):\r\n",
    "#             print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\r\n",
    "#             epoch, \r\n",
    "#             train_loss,\r\n",
    "#             valid_loss\r\n",
    "#             ))\r\n",
    "\r\n",
    "#     for data, target in enumerate(x_train_tensor,y_train_tensor):\r\n",
    "#         print(data.unsqueeze(dim=0))\r\n",
    "#         optimizer.zero_grad()\r\n",
    "        \r\n",
    "#         output = model(data)\r\n",
    "#         loss = critrian(output, target)\r\n",
    "#         critrian.backward()\r\n",
    "#         optimizer.step()\r\n",
    "#         train_loss = train_loss + loss.item()\r\n",
    "        \r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9f0a5a0a40bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# this section is for the apple stock model\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "file_csv = pd.read_csv(\"../csv_data/AAPL.csv\")\r\n",
    "\r\n",
    "file_csv.dropna(subset = [\"polarity\"], inplace=True)\r\n",
    "file_csv.dropna(subset = [\"subjectivity\"], inplace=True)\r\n",
    "file_csv.dropna(subset = [\"flag\"], inplace=True)\r\n",
    "\r\n",
    "polarity = file_csv[\"polarity\"].values\r\n",
    "subjectivity = file_csv[\"subjectivity\"].values\r\n",
    "flag = file_csv[\"flag\"].values\r\n",
    "\r\n",
    "polarity = np.array(polarity, dtype=np.float32)\r\n",
    "subjectivity = np.array(subjectivity, dtype=np.float32)\r\n",
    "flags = np.array(flag, dtype=np.float32)\r\n",
    "\r\n",
    "x_val = np.array(list(zip(polarity, subjectivity)), dtype=np.float32)\r\n",
    "y_val = np.array(flags, dtype=np.float32)\r\n",
    "\r\n",
    "\r\n",
    "x_train = np.array(list(zip(polarity, subjectivity)), dtype=np.float32)\r\n",
    "y_train = np.array(list(zip(flags, flags)), dtype=np.float32)\r\n",
    "\r\n",
    "x_train_tensor = torch.from_numpy(x_train)\r\n",
    "y_train_tensor = torch.from_numpy(y_train)\r\n",
    "data = (x_train_tensor, y_train_tensor)\r\n",
    "\r\n",
    "X_loader = torch.utils.data.DataLoader(x_train_tensor , batch_size = 2, shuffle = False)\r\n",
    "y_loader = torch.utils.data.DataLoader(y_train_tensor , batch_size = 2, shuffle = False)\r\n",
    "# data = next(iter(y_loader))\r\n",
    "# print(data)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "# define the model\r\n",
    "class Network(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Network, self).__init__()\r\n",
    "        self.fc1 = torch.nn.Linear(1, 64)\r\n",
    "        self.fc2 = torch.nn.Linear(64, 256)\r\n",
    "        self.fc3 = torch.nn.Linear(256, 500)\r\n",
    "        self.fc4 = torch.nn.Linear(500, 50)\r\n",
    "        self.fc5 = torch.nn.Linear(50, 1)\r\n",
    "        \r\n",
    "        self.drop = torch.nn.Dropout(0.2)\r\n",
    "#         self.double()\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.sigmoid((self.fc1(x)))\r\n",
    "\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.sigmoid((self.fc2(x)))\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.sigmoid((self.fc3(x)))\r\n",
    "        x = self.drop(x)\r\n",
    "        x = F.sigmoid((self.fc4(x)))\r\n",
    "        \r\n",
    "        out = F.hardtanh((self.fc5(x)))\r\n",
    "        return out\r\n",
    "model = Network()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "# optimizor and loss function\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\r\n",
    "critrian = torch.nn.L1Loss()\r\n",
    "# torch.nn.SoftMarginLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "# train loop\r\n",
    "train_loss = 0.0\r\n",
    "valid_loss = 0.0\r\n",
    "for epoch in range(100):\r\n",
    "    model.train()\r\n",
    "    \r\n",
    "    y_data = iter(y_loader)\r\n",
    "\r\n",
    "    for x in X_loader:\r\n",
    "        # print(x[:, :1])\r\n",
    "        x = x[:, :1]\r\n",
    "        # x = batch\r\n",
    "        # print(x[:, :1])\r\n",
    "        y = next(y_data)\r\n",
    "        y = y[:, :1]\r\n",
    "        # y = y[:, :1]\r\n",
    "        # print(y[0][0])\r\n",
    "        \r\n",
    "#         delete the second column from the tensor y\r\n",
    "        # y = y.numpy()\r\n",
    "        # y = np.delete(y, 1, 1)\r\n",
    "        # y = torch.from_numpy(y)\r\n",
    "        # print(y)\r\n",
    "        \r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "\r\n",
    "        output = model(x)\r\n",
    "        # print(output)\r\n",
    "        # break\r\n",
    "        # print(len(output[0]))\r\n",
    "    #     break\r\n",
    "    # break\r\n",
    "        loss = critrian(output, y)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        # train_loss =  train_loss + ((1/len(x)) * (loss.data.item()-train_loss))\r\n",
    "        train_loss +=   (1/len(x)) * loss.data.item()\r\n",
    "    # print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\r\n",
    "    #     epoch, \r\n",
    "    #         loss.item()))\r\n",
    "\r\n",
    "#\r\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\r\n",
    "            epoch, \r\n",
    "            train_loss))\r\n",
    "\r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 \tTraining Loss: 83.750000\n",
      "Epoch: 1 \tTraining Loss: 167.500000\n",
      "Epoch: 2 \tTraining Loss: 251.250000\n",
      "Epoch: 3 \tTraining Loss: 335.000000\n",
      "Epoch: 4 \tTraining Loss: 418.750000\n",
      "Epoch: 5 \tTraining Loss: 502.500000\n",
      "Epoch: 6 \tTraining Loss: 586.250000\n",
      "Epoch: 7 \tTraining Loss: 670.000000\n",
      "Epoch: 8 \tTraining Loss: 753.750000\n",
      "Epoch: 9 \tTraining Loss: 837.500000\n",
      "Epoch: 10 \tTraining Loss: 921.250000\n",
      "Epoch: 11 \tTraining Loss: 1005.000000\n",
      "Epoch: 12 \tTraining Loss: 1088.750000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-e060898acf2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcritrian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;31m# train_loss =  train_loss + ((1/len(x)) * (loss.data.item()-train_loss))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# this section is to make a function that provides prediction based on the polarities\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# file_csv = pd.read_csv(\"stock_market_prediction/csv_data/reuters_news.csv\")\r\n",
    "file_csv = pd.read_csv(\"../csv_data/reuters_news.csv\")\r\n",
    "file_csv\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ticker        date                                              title  \\\n",
       "0        CTAS  2020-03-19  BRIEF-Cintas Corp Reports Q3 Revenue Of $1.81 Bln   \n",
       "1        WELL  2020-04-17             BRIEF-Welltower Issues Business Update   \n",
       "2        WELL  2020-06-16  BRIEF-Welltower Files Prospectus Supplement Re...   \n",
       "3        WELL  2020-06-16  BRIEF-Welltower Announces Cash Tender Offer Fo...   \n",
       "4        WELL  2020-06-30  BRIEF-Welltower Announces Pricing Of Tender Of...   \n",
       "...       ...         ...                                                ...   \n",
       "644284    ZTS  2021-04-12                                                NaN   \n",
       "644285    ZTS  2021-04-13                                                NaN   \n",
       "644286    ZTS  2021-04-14                                                NaN   \n",
       "644287    ZTS  2021-04-15                                                NaN   \n",
       "644288    ZTS  2021-04-16                                                NaN   \n",
       "\n",
       "                                              description  polarity  \\\n",
       "0       cintas corp q3 revenue 1 81 billion versus ref...  0.025000   \n",
       "1       welltower inc welltower inc has elected to wit...  0.175595   \n",
       "2       welltower inc welltower says it files prospect... -0.033333   \n",
       "3       welltower inc welltower announces a cash tende... -0.083333   \n",
       "4       welltower inc welltower announces pricing of t...  0.062500   \n",
       "...                                                   ...       ...   \n",
       "644284                                                NaN       NaN   \n",
       "644285                                                NaN       NaN   \n",
       "644286                                                NaN       NaN   \n",
       "644287                                                NaN       NaN   \n",
       "644288                                                NaN       NaN   \n",
       "\n",
       "        subjectivity  prices  \n",
       "0           0.450000  180.71  \n",
       "1           0.563095   46.89  \n",
       "2           0.500000   55.89  \n",
       "3           0.416667   55.89  \n",
       "4           0.531250   50.18  \n",
       "...              ...     ...  \n",
       "644284           NaN  162.51  \n",
       "644285           NaN  163.47  \n",
       "644286           NaN  163.08  \n",
       "644287           NaN  165.45  \n",
       "644288           NaN  167.63  \n",
       "\n",
       "[644289 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTAS</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>BRIEF-Cintas Corp Reports Q3 Revenue Of $1.81 Bln</td>\n",
       "      <td>cintas corp q3 revenue 1 81 billion versus ref...</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>180.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELL</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>BRIEF-Welltower Issues Business Update</td>\n",
       "      <td>welltower inc welltower inc has elected to wit...</td>\n",
       "      <td>0.175595</td>\n",
       "      <td>0.563095</td>\n",
       "      <td>46.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELL</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>BRIEF-Welltower Files Prospectus Supplement Re...</td>\n",
       "      <td>welltower inc welltower says it files prospect...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELL</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>BRIEF-Welltower Announces Cash Tender Offer Fo...</td>\n",
       "      <td>welltower inc welltower announces a cash tende...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>55.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELL</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>BRIEF-Welltower Announces Pricing Of Tender Of...</td>\n",
       "      <td>welltower inc welltower announces pricing of t...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>50.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644284</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644285</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644286</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644287</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644288</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644289 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "source": [
    "# function to use as API for website\r\n",
    "def predict_price(data, ticker):\r\n",
    "    # get data for a specific ticker\r\n",
    "    ticker_data = data[data[\"ticker\"] == ticker]\r\n",
    "\r\n",
    "    # sort the data from recent to oldest\r\n",
    "    ticker_data.sort_values(by=['date'], inplace=True, ascending=False)\r\n",
    "\r\n",
    "    # clean data and get rid of not values\r\n",
    "    ticker_data.dropna(subset = [\"polarity\"], inplace=True)\r\n",
    "\r\n",
    "    # get polarities and convert them to numpay array for speed\r\n",
    "    polarity = ticker_data[\"polarity\"].values\r\n",
    "    polarity = np.array(polarity, dtype=np.float32)\r\n",
    "\r\n",
    "\r\n",
    "    # calculate average of the past 5 polarities\r\n",
    "    average = np.average(polarity[0:3])\r\n",
    "    print(average)\r\n",
    "\r\n",
    "\r\n",
    "    if average > 0.1:\r\n",
    "        print(\"Positive: price wil increase\")\r\n",
    "    elif average <= 0.1 or average >= -0.1:\r\n",
    "        print(\"Neutral: cannot predict price\")\r\n",
    "    else:\r\n",
    "        print(\"Nigative: price wil Decrease\")\r\n",
    "\r\n",
    "    # print(polarity[0:5])\r\n",
    "    # print(np.average( polarity[0:4]))\r\n",
    "\r\n",
    "\r\n",
    "predict_price(file_csv, \"AMAZ\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nan\n",
      "Nigative: price wil increase\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-255-41b5dcd445a0>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.sort_values(by=['date'], inplace=True, ascending=False)\n",
      "<ipython-input-255-41b5dcd445a0>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ticker_data.dropna(subset = [\"polarity\"], inplace=True)\n",
      "C:\\Users\\thabe\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\thabe\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "857b92bb1e7f37ea5458a7a77100e70dbda72f07c5fb9117ac4920a7d5bb010f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}