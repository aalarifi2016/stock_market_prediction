{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f45916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00c8ca8d-379e-4c73-aa71-c5d3634eebeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thabe\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "file_csv = pd.read_csv(\"stock_market_prediction/csv_data/reuters_news.csv\")\n",
    "\n",
    "# cleaning data by removing raws that has null values in the polarity, subjectivity, or prices columns \n",
    "file_csv.dropna(subset = [\"polarity\"], inplace=True)\n",
    "file_csv.dropna(subset = [\"subjectivity\"], inplace=True)\n",
    "file_csv.dropna(subset = [\"prices\"], inplace=True)\n",
    "\n",
    "# getting the values of each column\n",
    "polarity = file_csv[\"polarity\"].values\n",
    "subjectivity = file_csv[\"subjectivity\"].values\n",
    "prices = file_csv[\"prices\"].values\n",
    "\n",
    "\n",
    "# making pairwise 2d-array of the polarity and subjectivity arrays\n",
    "polarity = np.array(polarity, dtype=np.float32)\n",
    "subjectivity = np.array(subjectivity, dtype=np.float32)\n",
    "prices = np.array(prices, dtype=np.float32)\n",
    "\n",
    "\n",
    "# devide data into testing, and training, and validation \n",
    "x_val = np.array(list(zip(polarity[:5000], subjectivity[:5000])), dtype=np.float32)\n",
    "y_val = np.array(prices[:5000], dtype=np.float32)\n",
    "\n",
    "x_train = np.array(list(zip(polarity[5000:24329], subjectivity[5000:24329])), dtype=np.float32)\n",
    "y_train = np.array(list(zip(prices[5000:24329], prices[5000:24329])), dtype=np.float32)    #had to change this for dataloader batch sizes equality, to avoid error\n",
    "# y_train.reshape((-1,2))\n",
    "\n",
    "x_test = np.array(list(zip(polarity[24329:], subjectivity[24329:])), dtype=np.float32)\n",
    "y_test = np.array(prices[24329:], dtype=np.float32)\n",
    "\n",
    "\n",
    "# creating the tensors to prepare data for the model\n",
    "x_val_tensor = torch.from_numpy(x_val)\n",
    "y_val_tensor = torch.from_numpy(y_val)\n",
    "y_val_tensor = y_val_tensor.to(torch.float64)\n",
    "\n",
    "\n",
    "# -----------------\n",
    "x_train_tensor = torch.from_numpy(x_train)\n",
    "# x_train_tensor = x_train_tensor.to(torch.float64)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "# y_train_tensor.resize(-1,2)\n",
    "# y_train_tensor.view(-1,2)\n",
    "# y_train_tensor = y_train_tensor.to(torch.float64)\n",
    "# -----------------\n",
    "\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "y_test_tensor = y_test_tensor.to(torch.float64)\n",
    "\n",
    "# for i in x_train:\n",
    "#     if len(i)<1:\n",
    "# for i in x_train:\n",
    "#     print(i)\n",
    "# train_loader = torch.utils.data.DataLoader(x_train_tensor, batch_size=20)\n",
    "\n",
    "# x_train_loader = torch.utils.data.DataLoader(x_train_tensor, 64, shuffle=False)\n",
    "# iter(x_train_loader).next()\n",
    "\n",
    "# training_data = np.array(list(zip(x_train, y_train)), dtype=np.float32)\n",
    "# training_data = torch.from_numpy(training_data)\n",
    "# x_train_loader = torch.utils.data.DataLoader(training_data, 64, shuffle=False)\n",
    "# iter(x_train_loader).next()\n",
    "dataloader = torch.utils.data.DataLoader((x_train_tensor, y_train_tensor) , batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ac7a750-1627-4b20-abdd-bf3d1cf42909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(2, 500)\n",
    "        self.fc2 = torch.nn.Linear(500, 1000)\n",
    "        self.fc3 = torch.nn.Linear(1000, 500)\n",
    "        self.fc4 = torch.nn.Linear(500, 50)\n",
    "        self.fc5 = torch.nn.Linear(50, 1)\n",
    "        \n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "#         self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        out = self.fc5(x)\n",
    "        return out\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3824b816-f66c-4f97-a760-938873ec4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "critrian = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a70defc-bf11-4f2e-9ed0-0bcd98c47a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 0.594454\n",
      "Epoch: 1 \tTraining Loss: 190.130099\n",
      "Epoch: 2 \tTraining Loss: 190.724353\n",
      "Epoch: 3 \tTraining Loss: 191.318507\n",
      "Epoch: 4 \tTraining Loss: 191.912561\n",
      "Epoch: 5 \tTraining Loss: 381.447794\n",
      "Epoch: 6 \tTraining Loss: 382.041648\n",
      "Epoch: 7 \tTraining Loss: 382.635403\n",
      "Epoch: 8 \tTraining Loss: 383.229057\n",
      "Epoch: 9 \tTraining Loss: 383.822611\n",
      "Epoch: 10 \tTraining Loss: 384.416065\n",
      "Epoch: 11 \tTraining Loss: 385.009420\n",
      "Epoch: 12 \tTraining Loss: 574.543965\n",
      "Epoch: 13 \tTraining Loss: 764.078404\n",
      "Epoch: 14 \tTraining Loss: 764.671459\n",
      "Epoch: 15 \tTraining Loss: 954.205700\n",
      "Epoch: 16 \tTraining Loss: 954.798554\n",
      "Epoch: 17 \tTraining Loss: 1144.332596\n",
      "Epoch: 18 \tTraining Loss: 1333.866547\n",
      "Epoch: 19 \tTraining Loss: 1523.400391\n",
      "Epoch: 20 \tTraining Loss: 1523.992845\n",
      "Epoch: 21 \tTraining Loss: 1524.585199\n",
      "Epoch: 22 \tTraining Loss: 1714.118754\n",
      "Epoch: 23 \tTraining Loss: 1714.710908\n",
      "Epoch: 24 \tTraining Loss: 1904.244248\n",
      "Epoch: 25 \tTraining Loss: 2093.777497\n",
      "Epoch: 26 \tTraining Loss: 2283.310639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-1c8a3dae7b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcritrian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0.0\n",
    "valid_loss = 0.0\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        \n",
    "#         delete the second column from the tensor y\n",
    "        y = y.numpy()\n",
    "        y = np.delete(y, 1, 1)\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "#         print(y)\n",
    "#         break\n",
    "#     break\n",
    "#         print(y[0][0])\n",
    "        # train model\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "        loss = critrian(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "# #       break\n",
    "# #   break\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss))\n",
    "\n",
    "    \n",
    "#     inputs = Variable(torch.from_numpy(x_train))\n",
    "#     labels = Variable(y_train_tensor)\n",
    "    \n",
    "# #     ---test----\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(inputs)\n",
    "#     loss = critrian(output, labels.float())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     train_loss += loss.item()\n",
    "    \n",
    "    # train model\n",
    "#     optimizer.zero_grad()\n",
    "        \n",
    "#     output = model(x_test_tensor.float())\n",
    "#     loss = critrian(output, y_test_tensor.float())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     train_loss += loss.item()\n",
    "    \n",
    "#     model.eval()\n",
    "#     output = model(x_test_tensor.float())\n",
    "#     loss = critrian(output, y_test_tensor.float())\n",
    "#     valid_loss += loss.item()\n",
    "\n",
    "#     if (10000%(epoch+1) == 0):\n",
    "#             print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "#             epoch, \n",
    "#             train_loss,\n",
    "#             valid_loss\n",
    "#             ))\n",
    "\n",
    "#     for data, target in enumerate(x_train_tensor,y_train_tensor):\n",
    "#         print(data.unsqueeze(dim=0))\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         output = model(data)\n",
    "#         loss = critrian(output, target)\n",
    "#         critrian.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loss = train_loss + loss.item()\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017fdf4e-2d11-47a3-95d1-99434e2d6ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
